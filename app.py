import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime
import streamlit_authenticator as stauth
import yaml
from yaml import SafeLoader

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å€‰åº«åˆ†æã‚¢ãƒ—ãƒªğŸ“¦",
    page_icon="ğŸ“¦",
    layout="wide",
    initial_sidebar_state="auto"
)

st.title("ğŸ“¦ å°ã•ãªå€‰åº«åˆ†æã‚¢ãƒ—ãƒª")

# èªè¨¼è¨­å®š
if "authenticator" not in st.session_state:
    credentials = {
        "usernames": {
            "zen": {
                "email": "zen@example.com",
                "name": "Zen",
                "password": stauth.Hasher.hash("password"),
            },
            "testuser": {
                "email": "test@example.com",
                "name": "ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼",
                "password": stauth.Hasher.hash("testpass"),
            }
        }
    }
    st.session_state.authenticator = stauth.Authenticate(
        credentials,
        cookie_name="warehouse_app",
        key="abcd",
        cookie_expiry_days=1,
    )

authenticator = st.session_state.authenticator
authenticator.login(
    location="sidebar",
    fields={"Form name": "ãƒ­ã‚°ã‚¤ãƒ³"}
)

# èªè¨¼çŠ¶æ…‹ã‚’å–å¾—
authentication_status = st.session_state.get("authentication_status")
username = st.session_state.get("username")
name = st.session_state.get("name")

if authentication_status is None:
    st.warning("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„")
    st.stop()
elif authentication_status is False:
    st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
    st.stop()

# ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³
st.sidebar.write(f"ğŸ‘¤ {name}")
if st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
    authenticator.logout(
        location="sidebar",
        button_name="ãƒ­ã‚°ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
    )
    st.experimental_rerun()

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded = st.file_uploader(
    "åœ¨åº«ãƒ‡ãƒ¼ã‚¿ (CSV ã¾ãŸã¯ Excel)",
    type=["csv", "xlsx", "xls"],
)

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
if uploaded:
    try:
        if uploaded.name.endswith(".csv"):
            df = pd.read_csv(uploaded)
        else:
            df = pd.read_excel(uploaded, engine="openpyxl")
        st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ« '{uploaded.name}' ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        st.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
    except Exception as e:
        st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()
else:
    st.info("ğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºä¸­...")
    df = pd.DataFrame(
        {
            "å•†å“ID": ["A01", "A02", "B01", "B02", "C01"],
            "å•†å“å": ["ãƒšãƒ³", "ãƒãƒ¼ãƒˆ", "ç®±", "ãƒ†ãƒ¼ãƒ—", "ã‚¯ãƒªãƒƒãƒ—"],
            "åœ¨åº«æ•°": [23, 5, 12, 3, 15],
            "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³": ["æ±äº¬", "å¤§é˜ª", "æ±äº¬", "å¤§é˜ª", "åå¤å±‹"],
            "æ›´æ–°æ—¥": [
                "2025-06-01",
                "2025-06-01",
                "2025-06-02",
                "2025-06-02",
                "2025-06-03",
            ],
        }
    )

# åˆ—åãƒãƒƒãƒ”ãƒ³ã‚°æ©Ÿèƒ½
def normalize_column_names(df):
    """åˆ—åã‚’æ¨™æº–å½¢å¼ã«ãƒãƒƒãƒ”ãƒ³ã‚°"""
    # åˆ—åãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸
    column_mapping = {
        # å•†å“ID ã®åˆ¥å
        "éƒ¨ç•ª": "å•†å“ID",
        "éƒ¨å“ç•ªå·": "å•†å“ID", 
        "è£½å“ç•ªå·": "å•†å“ID",
        "å“ç•ª": "å•†å“ID",
        "ã‚³ãƒ¼ãƒ‰": "å•†å“ID",
        "ID": "å•†å“ID",
        "å•†å“ã‚³ãƒ¼ãƒ‰": "å•†å“ID",
        
        # å•†å“å ã®åˆ¥å
        "éƒ¨å“å": "å•†å“å",
        "è£½å“å": "å•†å“å",
        "å“å": "å•†å“å",
        "åç§°": "å•†å“å",
        "å•†å“": "å•†å“å",
        "ã‚¢ã‚¤ãƒ†ãƒ å": "å•†å“å",
        
        # åœ¨åº«æ•° ã®åˆ¥å
        "æ•°é‡": "åœ¨åº«æ•°",
        "åœ¨åº«": "åœ¨åº«æ•°",
        "æ®‹æ•°": "åœ¨åº«æ•°",
        "ä¿æœ‰æ•°": "åœ¨åº«æ•°",
        "ç¾åœ¨åº«": "åœ¨åº«æ•°",
        "åœ¨åº«é‡": "åœ¨åº«æ•°",
        "QTY": "åœ¨åº«æ•°",
        "qty": "åœ¨åº«æ•°",
        
        # ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã®åˆ¥å
        "æ‰€åœ¨åœ°": "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
        "æ£šç•ªå·": "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
        "æ£šç•ª": "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
        "å€‰åº«": "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
        "å ´æ‰€": "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
        "ä¿ç®¡å ´æ‰€": "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
        "ä½ç½®": "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
        "ã‚¨ãƒªã‚¢": "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
        "æ‹ ç‚¹": "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
        "ã‚¾ãƒ¼ãƒ³": "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
    }
    
    # åˆ—åã‚’æ­£è¦åŒ–
    df_normalized = df.copy()
    renamed_columns = {}
    
    for old_col in df.columns:
        if old_col in column_mapping:
            new_col = column_mapping[old_col]
            renamed_columns[old_col] = new_col
    
    if renamed_columns:
        df_normalized = df_normalized.rename(columns=renamed_columns)
        st.info(f"ğŸ”„ åˆ—åã‚’å¤‰æ›ã—ã¾ã—ãŸ: {renamed_columns}")
    
    return df_normalized, renamed_columns

# åˆ—åã®æ­£è¦åŒ–ã‚’å®Ÿè¡Œ
df, renamed_cols = normalize_column_names(df)

# ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
with st.expander("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=False):
    st.write("**ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å½¢çŠ¶:**", df.shape)
    st.write("**åˆ—å:**", list(df.columns))
    if renamed_cols:
        st.write("**å¤‰æ›ã•ã‚ŒãŸåˆ—å:**", renamed_cols)
    st.write("**ãƒ‡ãƒ¼ã‚¿å‹:**", df.dtypes.to_dict())
    st.write("**æœ€åˆã®5è¡Œ:**")
    st.dataframe(df.head())

# ãƒ‡ãƒ¼ã‚¿ã®åˆ—åãƒã‚§ãƒƒã‚¯ã¨ä¿®æ­£
required_columns = ["å•†å“ID", "å•†å“å", "åœ¨åº«æ•°", "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³"]
missing_columns = [col for col in required_columns if col not in df.columns]

if missing_columns:
    st.error(f"âŒ å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}")
    
    # åˆ—åãƒãƒƒãƒ”ãƒ³ã‚°ã®ææ¡ˆ
    st.info("ğŸ“ ä»¥ä¸‹ã®åˆ—åã«å¯¾å¿œã—ã¦ã„ã¾ã™:")
    
    st.markdown("**å•†å“ID ã¨ã—ã¦èªè­˜ã•ã‚Œã‚‹åˆ—å:**")
    st.write("éƒ¨ç•ª, éƒ¨å“ç•ªå·, è£½å“ç•ªå·, å“ç•ª, ã‚³ãƒ¼ãƒ‰, ID, å•†å“ã‚³ãƒ¼ãƒ‰")
    
    st.markdown("**å•†å“å ã¨ã—ã¦èªè­˜ã•ã‚Œã‚‹åˆ—å:**")
    st.write("éƒ¨å“å, è£½å“å, å“å, åç§°, å•†å“, ã‚¢ã‚¤ãƒ†ãƒ å")
    
    st.markdown("**åœ¨åº«æ•° ã¨ã—ã¦èªè­˜ã•ã‚Œã‚‹åˆ—å:**")
    st.write("æ•°é‡, åœ¨åº«, æ®‹æ•°, ä¿æœ‰æ•°, ç¾åœ¨åº«, åœ¨åº«é‡, QTY, qty")
    
    st.markdown("**ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã¨ã—ã¦èªè­˜ã•ã‚Œã‚‹åˆ—å:**")
    st.write("æ‰€åœ¨åœ°, æ£šç•ªå·, æ£šç•ª, å€‰åº«, å ´æ‰€, ä¿ç®¡å ´æ‰€, ä½ç½®, ã‚¨ãƒªã‚¢, æ‹ ç‚¹, ã‚¾ãƒ¼ãƒ³")
    
    # åˆ©ç”¨å¯èƒ½ãªåˆ—ã‚’è¡¨ç¤º
    st.write("**ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã®åˆ—:**")
    for i, col in enumerate(df.columns, 1):
        st.write(f"{i}. {col}")
    
    # æ‰‹å‹•ãƒãƒƒãƒ”ãƒ³ã‚°æ©Ÿèƒ½
    st.markdown("### ğŸ”§ æ‰‹å‹•åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°")
    if st.checkbox("æ‰‹å‹•ã§åˆ—ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹"):
        available_columns = [""] + list(df.columns)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            id_col = st.selectbox("å•†å“IDåˆ—ã‚’é¸æŠ", available_columns)
        with col2:
            name_col = st.selectbox("å•†å“ååˆ—ã‚’é¸æŠ", available_columns)
        with col3:
            stock_col = st.selectbox("åœ¨åº«æ•°åˆ—ã‚’é¸æŠ", available_columns)
        with col4:
            location_col = st.selectbox("ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ—ã‚’é¸æŠ", available_columns)
        
        if all([id_col, name_col, stock_col, location_col]):
            # æ‰‹å‹•ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨
            manual_mapping = {
                id_col: "å•†å“ID",
                name_col: "å•†å“å", 
                stock_col: "åœ¨åº«æ•°",
                location_col: "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³"
            }
            df = df.rename(columns=manual_mapping)
            st.success(f"âœ… æ‰‹å‹•ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨ã—ã¾ã—ãŸ: {manual_mapping}")
        else:
            st.warning("ã™ã¹ã¦ã®åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„")
            st.stop()
    else:
        st.stop()

# æ—¥ä»˜å‹å¤‰æ›
if "æ›´æ–°æ—¥" in df.columns:
    try:
        if pd.api.types.is_object_dtype(df["æ›´æ–°æ—¥"]):
            df["æ›´æ–°æ—¥"] = pd.to_datetime(df["æ›´æ–°æ—¥"])
        st.success("âœ… æ›´æ–°æ—¥ã‚’æ—¥ä»˜å‹ã«å¤‰æ›ã—ã¾ã—ãŸ")
    except Exception as e:
        st.warning(f"âš ï¸ æ—¥ä»˜å¤‰æ›ã«å¤±æ•—: {e}")

# æ•°å€¤å‹å¤‰æ›ï¼ˆåœ¨åº«æ•°ï¼‰
if "åœ¨åº«æ•°" in df.columns:
    try:
        df["åœ¨åº«æ•°"] = pd.to_numeric(df["åœ¨åº«æ•°"], errors="coerce")
        # NaNã®å‡¦ç†
        if df["åœ¨åº«æ•°"].isna().any():
            na_count = df["åœ¨åº«æ•°"].isna().sum()
            st.warning(f"âš ï¸ åœ¨åº«æ•°ã«æ•°å€¤ä»¥å¤–ã®ãƒ‡ãƒ¼ã‚¿ãŒ{na_count}ä»¶ã‚ã‚Šã¾ã—ãŸã€‚0ã«ç½®æ›ã—ã¾ã™ã€‚")
            df["åœ¨åº«æ•°"] = df["åœ¨åº«æ•°"].fillna(0)
        st.success("âœ… åœ¨åº«æ•°ã‚’æ•°å€¤å‹ã«å¤‰æ›ã—ã¾ã—ãŸ")
    except Exception as e:
        st.warning(f"âš ï¸ åœ¨åº«æ•°ã®æ•°å€¤å¤‰æ›ã«å¤±æ•—: {e}")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
low_stock_threshold = st.sidebar.number_input(
    "åœ¨åº«ä¸è¶³åˆ¤å®šã—ãã„å€¤", min_value=0, value=10
)

# KPIè¨ˆç®—ã¨ãƒ‡ãƒãƒƒã‚°
try:
    total_products = len(df)
    total_stock = int(df["åœ¨åº«æ•°"].sum())
    low_stock_items = int((df["åœ¨åº«æ•°"] < low_stock_threshold).sum())
    
    # KPIè¡¨ç¤º
    col1, col2, col3 = st.columns(3)
    col1.metric("ç·å•†å“æ•°", total_products)
    col2.metric("ç·åœ¨åº«æ•°", total_stock)
    col3.metric("åœ¨åº«ä¸è¶³å“ç›®", low_stock_items)
    
except Exception as e:
    st.error(f"âŒ KPIè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
    st.write("ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ‡ãƒ¼ã‚¿:")
    st.write(df)

# ãƒŸãƒ‹åœ¨åº«æ¤œç´¢
st.markdown("### ğŸ” ãƒŸãƒ‹åœ¨åº«æ¤œç´¢")
search_term = st.text_input("å•†å“åã¾ãŸã¯IDã§æ¤œç´¢", "")

if search_term:
    try:
        result_df = df[
            df["å•†å“å"].str.contains(search_term, case=False, na=False) |
            df["å•†å“ID"].str.contains(search_term, case=False, na=False)
        ]
        if not result_df.empty:
            st.success(f"ğŸ¯ {len(result_df)}ä»¶ã®å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            st.dataframe(result_df, hide_index=True, height=250)
        else:
            st.info("è©²å½“ã™ã‚‹å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    except Exception as e:
        st.error(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")

# ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
try:
    unique_locations = sorted(df["ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³"].unique())
    locations = st.multiselect(
        "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é¸æŠ",
        options=unique_locations,
        default=unique_locations,
    )
    
    if locations:
        df_filtered = df[df["ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³"].isin(locations)]
        st.success(f"âœ… {len(locations)}ãƒ¶æ‰€ã®ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
    else:
        df_filtered = df
        st.warning("âš ï¸ ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…¨ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
        
except Exception as e:
    st.error(f"âŒ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    df_filtered = df

# åœ¨åº«ä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ«
st.subheader("ğŸ“‹ åœ¨åº«ä¸€è¦§")
try:
    if not df_filtered.empty:
        # ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ä»˜ããƒ†ãƒ¼ãƒ–ãƒ«
        styled_df = df_filtered.style.apply(
            lambda x: [
                "background-color:#FFCDD2" if v < low_stock_threshold else ""
                for v in x
            ],
            subset=["åœ¨åº«æ•°"],
        )
        st.dataframe(styled_df, hide_index=True, height=350)
        
        # çµ±è¨ˆæƒ…å ±
        st.markdown("**ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®çµ±è¨ˆ:**")
        col1, col2, col3 = st.columns(3)
        col1.metric("è¡¨ç¤ºå•†å“æ•°", len(df_filtered))
        col2.metric("è¡¨ç¤ºåœ¨åº«ç·æ•°", int(df_filtered["åœ¨åº«æ•°"].sum()))
        col3.metric("åœ¨åº«ä¸è¶³å•†å“", int((df_filtered["åœ¨åº«æ•°"] < low_stock_threshold).sum()))
    else:
        st.warning("âš ï¸ è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        
except Exception as e:
    st.error(f"âŒ ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
    st.write("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®ãƒ‡ãƒ¼ã‚¿:")
    st.write(df_filtered)

# æ“ä½œå±¥æ­´ç”¨ãƒªã‚¹ãƒˆåˆæœŸåŒ–
if "ops" not in st.session_state:
    st.session_state.ops = []

# KPIç®—å‡ºç›´å¾Œã«å±¥æ­´ç™»éŒ²
st.session_state.ops.append({
    "time": datetime.now().isoformat(timespec="seconds"),
    "action": "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿",
    "records": len(df),
    "user": name,
    "column_mapping": renamed_cols if renamed_cols else "ãªã—"
})

# å¯è¦–åŒ–ã‚¿ãƒ–
try:
    barcode_tab, inv_tab, trend_tab = st.tabs(["ğŸ“· ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã‚¹ã‚­ãƒ£ãƒ³", "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥åœ¨åº«", "æ—¥åˆ¥åœ¨åº«æ¨ç§»"])

    with barcode_tab:
        st.subheader("ğŸ“± ãƒãƒ¼ã‚³ãƒ¼ãƒ‰/QR èª­ã¿å–ã‚Š")
        st.info("ğŸ“¡ ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯HTTPSç’°å¢ƒãŒå¿…è¦ã§ã™")
        
        try:
            from streamlit_qrcode_scanner import qrcode_scanner as qr_scanner
            code = qr_scanner("ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•")
            if code:
                st.success(f"âœ… èª­ã¿å–ã‚Šçµæœ: {code}")
                
                # èª­ã¿å–ã£ãŸã‚³ãƒ¼ãƒ‰ã§å•†å“ã‚’æ¤œç´¢
                search_result = df[
                    df["å•†å“ID"].str.contains(str(code), case=False, na=False) |
                    df["å•†å“å"].str.contains(str(code), case=False, na=False)
                ]
                
                if not search_result.empty:
                    st.subheader("ğŸ¯ è©²å½“å•†å“")
                    st.dataframe(search_result, hide_index=True)
                else:
                    st.warning("è©²å½“ã™ã‚‹å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
                # å±¥æ­´ã«è¨˜éŒ²
                st.session_state.ops.append({
                    "time": datetime.now().isoformat(timespec="seconds"),
                    "action": "ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã‚¹ã‚­ãƒ£ãƒ³",
                    "code": str(code),
                    "result": len(search_result),
                    "user": name
                })
        except ImportError:
            st.error("ğŸ“¦ streamlit-qrcode-scanner ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            st.code("pip install streamlit-qrcode-scanner", language="bash")
        except Exception as e:
            st.error(f"âŒ ã‚¹ã‚­ãƒ£ãƒŠãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æ‰‹å‹•å…¥åŠ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.markdown("---")
        st.subheader("âŒ¨ï¸ æ‰‹å‹•å…¥åŠ›")
        manual_code = st.text_input("å•†å“IDã¾ãŸã¯ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›", "")
        if manual_code:
            search_result = df[df["å•†å“ID"].str.contains(manual_code, case=False, na=False)]
            if not search_result.empty:
                st.dataframe(search_result, hide_index=True)
            else:
                st.info("è©²å½“ã™ã‚‹å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    with inv_tab:
        if not df_filtered.empty:
            location_summary = df_filtered.groupby("ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³")["åœ¨åº«æ•°"].sum().reset_index()
            
            if not location_summary.empty:
                fig_loc = px.bar(
                    location_summary,
                    x="ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
                    y="åœ¨åº«æ•°",
                    title="ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥ åœ¨åº«ç·æ•°",
                    color="åœ¨åº«æ•°",
                    color_continuous_scale="viridis",
                )
                fig_loc.update_layout(
                    xaxis_title="ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³",
                    yaxis_title="åœ¨åº«æ•°",
                    showlegend=False
                )
                st.plotly_chart(fig_loc, use_container_width=True)
                
                # è©³ç´°ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
                st.markdown("**ğŸ“Š ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥è©³ç´°:**")
                st.dataframe(location_summary, hide_index=True)
            else:
                st.warning("âš ï¸ ã‚°ãƒ©ãƒ•è¡¨ç¤ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            st.warning("âš ï¸ è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    with trend_tab:
        if "æ›´æ–°æ—¥" in df_filtered.columns and not df_filtered.empty:
            try:
                daily = (
                    df_filtered.groupby(["æ›´æ–°æ—¥"])["åœ¨åº«æ•°"].sum().reset_index().sort_values("æ›´æ–°æ—¥")
                )
                
                if not daily.empty:
                    fig_day = px.line(
                        daily,
                        x="æ›´æ–°æ—¥",
                        y="åœ¨åº«æ•°",
                        markers=True,
                        title="æ—¥åˆ¥ åœ¨åº«æ¨ç§»",
                    )
                    fig_day.update_layout(
                        xaxis_title="æ›´æ–°æ—¥",
                        yaxis_title="åœ¨åº«æ•°"
                    )
                    st.plotly_chart(fig_day, use_container_width=True)
                    
                    # è©³ç´°ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
                    st.markdown("**ğŸ“Š æ—¥åˆ¥è©³ç´°:**")
                    st.dataframe(daily, hide_index=True)
                else:
                    st.warning("âš ï¸ æ—¥åˆ¥æ¨ç§»ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            except Exception as e:
                st.error(f"âŒ æ—¥åˆ¥æ¨ç§»ã‚°ãƒ©ãƒ•ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.info("ğŸ“… ã€æ›´æ–°æ—¥ã€ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€æ—¥åˆ¥åœ¨åº«æ¨ç§»ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

except Exception as e:
    st.error(f"âŒ ã‚¿ãƒ–è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")

# æ“ä½œå±¥æ­´ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
with st.sidebar:
    st.markdown("### ğŸ“ æ“ä½œå±¥æ­´")
    if len(st.session_state.ops) > 0:
        st.write(f"è¨˜éŒ²æ•°: {len(st.session_state.ops)}")
        if st.button("å±¥æ­´ã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
            import json, base64
            hist = json.dumps(st.session_state.ops, ensure_ascii=False, indent=2)
            b64 = base64.b64encode(hist.encode()).decode()
            href = f'<a href="data:application/json;base64,{b64}" download="ops_history.json">ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
            st.markdown(href, unsafe_allow_html=True)
    else:
        st.write("å±¥æ­´ãªã—")

st.markdown("---")
st.caption(
    f"æœ€çµ‚æ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | Powered by Streamlit | ãƒ¦ãƒ¼ã‚¶ãƒ¼: {name}"
)
